{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as _hex_pandas\n",
    "import datetime as _hex_datetime\n",
    "import json as _hex_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_scheduled = _hex_json.loads(\"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_user_email = _hex_json.loads(\"\\\"example-user@example.com\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_user_attributes = _hex_json.loads(\"{}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_run_context = _hex_json.loads(\"\\\"logic\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_timezone = _hex_json.loads(\"\\\"UTC\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_project_id = _hex_json.loads(\"\\\"70dd2a3e-c68b-4b52-b832-56ae5d562af4\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_project_name = _hex_json.loads(\"\\\"CUMULATIVE CHALLENGE: Daily Visitors Forecasting_Learners Guide\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_status = _hex_json.loads(\"\\\"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_categories = _hex_json.loads(\"[]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_color_palette = _hex_json.loads(\"[\\\"#4C78A8\\\",\\\"#F58518\\\",\\\"#E45756\\\",\\\"#72B7B2\\\",\\\"#54A24B\\\",\\\"#EECA3B\\\",\\\"#B279A2\\\",\\\"#FF9DA6\\\",\\\"#9D755D\\\",\\\"#BAB0AC\\\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1- Upload Datasets into Snowflake Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Snowflake UI to upload DAILY_VISITORS.csv & DAILY_VISITORS_NEW.csv into Snowflake Internal Stage then create 2 Tables\n",
    "\n",
    "1. _**DAILY_VISITORS **_,which contains 5 years of historical daily visitors.\n",
    "2. _**DAILY_VISITORS_NEW**_, which is a new month (November) for which we want to predict the number of daily visitors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2- Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowpark for Python\n",
    "from snowflake.snowpark.functions import udf\n",
    "from snowflake.snowpark import types as T\n",
    "import snowflake.snowpark.functions as F\n",
    "from snowflake.snowpark.version import VERSION\n",
    "\n",
    "\n",
    "# Snowpark ML\n",
    "from snowflake.ml.modeling.xgboost import XGBRegressor\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.ml.modeling.preprocessing import OrdinalEncoder\n",
    "\n",
    "# data science libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from snowflake.ml.modeling.metrics import r2_score\n",
    "\n",
    "# misc\n",
    "import joblib\n",
    "import cachetools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3- Create Snowpark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User                        : JAMESMCINTYRE\n",
      "Role                        : \"ACCOUNTADMIN\"\n",
      "Database                    : \"VISITORS\"\n",
      "Schema                      : \"PUBLIC\"\n",
      "Warehouse                   : \"PC_HEX_WH\"\n",
      "Snowflake version           : 9.5.2\n",
      "Snowpark for Python version : 1.28.0\n"
     ]
    }
   ],
   "source": [
    "from snowflake.snowpark import Session\n",
    "session = Session.builder.config(\"connection_name\", 'VISITORS_CONNECTION',).create()\n",
    "\n",
    "# Verify connectivity to Snowflake\n",
    "snowflake_environment = session.sql('SELECT current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4- Import Daily Visitors Historical Data as a Snowpark DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"CALENDAR_DATE\"  |\"DAY\"      |\"CALENDAR_MTH_DAY_NBR\"  |\"CALENDAR_MTH\"  |\"CALENDAR_YEAR\"  |\"HOLIDAY\"  |\"LAST_YEAR_DAILY_VISITORS\"  |\"DAILY_VISITORS\"  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|2018-06-16       |SATURDAY   |16                      |6               |2018             |1          |71                          |89                |\n",
      "|2018-06-17       |SUNDAY     |17                      |6               |2018             |1          |79                          |99                |\n",
      "|2018-06-18       |MONDAY     |18                      |6               |2018             |0          |97                          |108               |\n",
      "|2018-06-19       |TUESDAY    |19                      |6               |2018             |0          |42                          |46                |\n",
      "|2018-06-20       |WEDNESDAY  |20                      |6               |2018             |0          |30                          |34                |\n",
      "|2018-06-21       |THURSDAY   |21                      |6               |2018             |0          |32                          |36                |\n",
      "|2018-06-22       |FRIDAY     |22                      |6               |2018             |0          |38                          |43                |\n",
      "|2018-06-23       |SATURDAY   |23                      |6               |2018             |1          |72                          |90                |\n",
      "|2018-06-24       |SUNDAY     |24                      |6               |2018             |1          |77                          |96                |\n",
      "|2018-06-25       |MONDAY     |25                      |6               |2018             |0          |101                         |112               |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"SUMMARY\"  |\"DAY\"      |\"CALENDAR_MTH_DAY_NBR\"  |\"CALENDAR_MTH\"     |\"CALENDAR_YEAR\"     |\"HOLIDAY\"            |\"LAST_YEAR_DAILY_VISITORS\"  |\"DAILY_VISITORS\"   |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|count      |1599       |1599.0                  |1599.0             |1599.0              |1599.0               |1599.0                      |1599.0             |\n",
      "|mean       |NULL       |15.809256               |6.669794           |2020.131332         |0.314572             |58.877423                   |68.804253          |\n",
      "|stddev     |NULL       |8.805392268377371       |3.354302610081565  |1.3033173059543097  |0.46449004295033064  |25.143019886242783          |30.95151170783101  |\n",
      "|min        |FRIDAY     |1.0                     |1.0                |2018.0              |0.0                  |26.0                        |32.0               |\n",
      "|max        |WEDNESDAY  |31.0                    |12.0               |2022.0              |1.0                  |110.0                       |122.0              |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Snowpark DF for Table DAILY_VISITORS\n",
    "VISITORS_TABLE = 'DAILY_VISITORS'\n",
    "input_tbl = f\"{session.get_current_database()}.{session.get_current_schema()}.{VISITORS_TABLE}\"\n",
    "input_tbl\n",
    "\n",
    "# Show Snowpark DF \n",
    "# First, we read-in the data from a Snowflake table into a Snowpark DataFrame\n",
    "DAILY_VISITORS_DF = session.table(input_tbl)\n",
    "\n",
    "# Let's visualise the Data\n",
    "DAILY_VISITORS_DF.show()\n",
    "\n",
    "# Describe Snowpark Datafarame\n",
    "DAILY_VISITORS_DF.describe().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___**NOTES**___ : \n",
    "\n",
    "- ',**DAY**,' is a Categorical column. You will need to transform it into Numerical column using OrdinalEncoder Transformer. \n",
    "- ',**CALENDAR_DATE**,' will be replaced by 'CALENDAR_MTH_DAY_NBR', 'CALENDAR_MTH' and 'CALENDAR_YEAR' columns.\n",
    "- ',**HOLIDAY**,' column indicates if that day was a public Holiday or a Weekend. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5- Split the dataset into Training and Test DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"SUMMARY\"  |\"DAY\"      |\"CALENDAR_MTH_DAY_NBR\"  |\"CALENDAR_MTH\"      |\"CALENDAR_YEAR\"  |\"HOLIDAY\"            |\"LAST_YEAR_DAILY_VISITORS\"  |\"DAILY_VISITORS\"   |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|count      |61         |61.0                    |61.0                |61.0             |61.0                 |61.0                        |61.0               |\n",
      "|mean       |NULL       |15.754098               |9.508197            |2022.0           |0.327869             |61.95082                    |72.672131          |\n",
      "|stddev     |NULL       |8.880044538176596       |0.5040813426422367  |0.0              |0.47333286384953244  |25.63553927655902           |32.05657567489079  |\n",
      "|max        |WEDNESDAY  |31.0                    |10.0                |2022.0           |1.0                  |108.0                       |121.0              |\n",
      "|min        |FRIDAY     |1.0                     |9.0                 |2022.0           |0.0                  |34.0                        |38.0               |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Since our dataset is a timeseries, we will split it based on a cut-off date (not a random split) to preserve the order and structure.  \n",
    "split_date = '01-Sep-2022'\n",
    "\n",
    "# Create Train DF \n",
    "train_df = DAILY_VISITORS_DF\\\n",
    "    .select('DAY',\\\n",
    "            'CALENDAR_MTH_DAY_NBR',\\\n",
    "            'CALENDAR_MTH',\\\n",
    "            'CALENDAR_YEAR',\\\n",
    "            'HOLIDAY',\\\n",
    "            'LAST_YEAR_DAILY_VISITORS',\\\n",
    "            'DAILY_VISITORS').\\\n",
    "    filter((F.col('CALENDAR_DATE') < split_date))\n",
    "\n",
    "# Create Test DF Similar to Train_DF \n",
    "test_df = DAILY_VISITORS_DF\\\n",
    "    .select('DAY',\\\n",
    "            'CALENDAR_MTH_DAY_NBR',\\\n",
    "            'CALENDAR_MTH',\\\n",
    "            'CALENDAR_YEAR',\\\n",
    "            'HOLIDAY',\\\n",
    "            'LAST_YEAR_DAILY_VISITORS',\\\n",
    "            'DAILY_VISITORS').\\\n",
    "    filter((F.col('CALENDAR_DATE') >= split_date))\n",
    "\n",
    "# NOTE : both 'CALENDAR_DATE' & 'HOLIDAY_NAME' columns are dropped from our DF and will not be used further. \n",
    "# 'CALENDAR_DATE' will be replaced by 'CALENDAR_MTH_DAY_NBR', 'CALENDAR_MTH' and 'CALENDAR_YEAR' columns.\n",
    "\n",
    "\n",
    "# Show train_df\n",
    "test_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6- Categorize columns & Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize all the features for modeling\n",
    "CATEGORICAL_COLUMNS = [\"DAY\"]\n",
    "CATEGORICAL_COLUMNS_OE = [\"CALENDAR_WEEK_DAY_NBR\"]\n",
    "NUMERICAL_COLUMNS = ['CALENDAR_MTH_DAY_NBR','CALENDAR_MTH','CALENDAR_YEAR','HOLIDAY','LAST_YEAR_DAILY_VISITORS']\n",
    "LABEL_COLUMNS = ['DAILY_VISITORS']\n",
    "OUTPUT_COLUMNS = ['FORECASTED_DAILY_VISITORS']\n",
    "\n",
    "# Create categories to be used in the OrdinalEncoder transformer. \n",
    "categories = {\n",
    "    \"DAY\": np.array([\"MONDAY\", \"TUESDAY\", \"WEDNESDAY\", \"THURSDAY\", \"FRIDAY\", \"SATURDAY\", \"SUNDAY\"]),\n",
    "}\n",
    "\n",
    "# Define a pipeline that does the preprocessing (OrdinalEncoder) for column DAY and Regressor (using XGBRegressor model)\n",
    "pipe = pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"OE\", OrdinalEncoder(\n",
    "            input_cols= CATEGORICAL_COLUMNS,  \n",
    "            output_cols= CATEGORICAL_COLUMNS_OE, \n",
    "            categories = categories,  \n",
    "            drop_input_cols=True)\n",
    "            ),\n",
    "        (\"regressor\", XGBRegressor(\n",
    "            learning_rate = 0.1, # Add Best best_params_ Results here \n",
    "            n_estimators = 200,  # Add Best best_params_ Results here \n",
    "            input_cols=CATEGORICAL_COLUMNS_OE + NUMERICAL_COLUMNS, \n",
    "            label_cols=LABEL_COLUMNS, \n",
    "            output_cols=OUTPUT_COLUMNS, \n",
    "            n_jobs=-1)\n",
    "            )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7- Train the model and check its accuracy using R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Package 'snowflake-telemetry-python' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
      "c:\\Users\\James\\snowflaketest39\\lib\\site-packages\\snowflake\\ml\\model\\model_signature.py:74: UserWarning: The sample input has 1538 rows, thus a truncation happened before inferring signature. This might cause inaccurate signature inference. If that happens, consider specifying signature manually.\n",
      "  warnings.warn(\n",
      "c:\\Users\\James\\snowflaketest39\\lib\\site-packages\\snowflake\\ml\\model\\model_signature.py:74: UserWarning: The sample input has 1538 rows, thus a truncation happened before inferring signature. This might cause inaccurate signature inference. If that happens, consider specifying signature manually.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.ml.modeling.pipeline.pipeline.Pipeline at 0x2e901c09c40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model by calling .fit()\n",
    "pipe.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "|\"DAILY_VISITORS\"  |\"FORECASTED_DAILY_VISITORS\"  |\n",
      "--------------------------------------------------\n",
      "|38                |37.7777099609375             |\n",
      "|47                |46.33698272705078            |\n",
      "|98                |97.64281463623047            |\n",
      "|110               |110.20867156982422           |\n",
      "|118               |117.42937469482422           |\n",
      "|50                |50.233856201171875           |\n",
      "|44                |44.536285400390625           |\n",
      "|41                |41.11422348022461            |\n",
      "|48                |48.12749481201172            |\n",
      "|99                |99.13192749023438            |\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9998043185608769"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forecast daily visitors for test_df\n",
    "result = pipe.predict(test_df)\n",
    "\n",
    "# Show results\n",
    "result.select(\"DAILY_VISITORS\", \"FORECASTED_DAILY_VISITORS\").show()\n",
    "\n",
    "# calculate Model Accuracy using R-2 Score \n",
    "r2_score(df=result, y_true_col_name=\"DAILY_VISITORS\", y_pred_col_name='FORECASTED_DAILY_VISITORS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ___NOTE : ___No need for GridSearchCV for hyper-parameters tuning  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8- Convert pipeline to sklearn file and Save it into Snowflake Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Package 'snowflake-telemetry-python' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
      "c:\\Users\\James\\snowflaketest39\\lib\\site-packages\\snowflake\\ml\\model\\model_signature.py:74: UserWarning: The sample input has 1538 rows, thus a truncation happened before inferring signature. This might cause inaccurate signature inference. If that happens, consider specifying signature manually.\n",
      "  warnings.warn(\n",
      "c:\\Users\\James\\snowflaketest39\\lib\\site-packages\\snowflake\\ml\\model\\model_signature.py:74: UserWarning: The sample input has 1538 rows, thus a truncation happened before inferring signature. This might cause inaccurate signature inference. If that happens, consider specifying signature manually.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PutResult(source='daily_visitors_model.joblib', target='daily_visitors_model.joblib', source_size=701851, target_size=701856, source_compression='NONE', target_compression='NONE', status='UPLOADED', message='')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call pipe.fit(train_df) then convert Model into SKLEARN Object using to_sklearn()\n",
    "model = pipe.fit(train_df).to_sklearn()\n",
    "\n",
    "# Save the model locally as joblib\n",
    "MODEL_FILE = 'daily_visitors_model.joblib'\n",
    "\n",
    "joblib.dump(model, MODEL_FILE)\n",
    "\n",
    "# Upload the model's joblib file into the Snowflake stage ML_FILES \n",
    "session.file.put(MODEL_FILE, \"@ML_FILES\", overwrite=True, auto_compress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9- Create Vectorised UDF for Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read the model from a file\n",
    "@cachetools.cached(cache={})\n",
    "def read_file(filename):\n",
    "    import joblib\n",
    "    import sys\n",
    "    import os\n",
    "\n",
    "    IMPORT_DIRECTORY_NAME = \"snowflake_import_directory\"\n",
    "    import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]\n",
    "\n",
    "    if import_dir:\n",
    "        with open(os.path.join(import_dir, filename), 'rb') as file:\n",
    "            m = joblib.load(file)\n",
    "            return m\n",
    "\n",
    "\n",
    "# Create a vectorized UDF for batch inference\n",
    "@F.udf(name=\"predict_daily_visitors\",\n",
    "        is_permanent=True,\n",
    "        stage_location = '@ML_FILES',\n",
    "        imports=['@ML_FILES/daily_visitors_model.joblib'],\n",
    "        packages=['snowflake-ml-python', 'joblib', 'scikit-learn==1.5.2', 'xgboost==2.1.1', 'cachetools'],\n",
    "        replace=True,\n",
    "        session=session)\n",
    "def predict_daily_visitors(pd_input: T.PandasDataFrame[str, float, float, float, float, float]) -> T.PandasSeries[float]:\n",
    "        # Make sure you have the columns in the expected order in the Pandas DataFrame\n",
    "    features = ['DAY', 'CALENDAR_MTH_DAY_NBR', 'CALENDAR_MTH', 'CALENDAR_YEAR', 'HOLIDAY', 'LAST_YEAR_DAILY_VISITORS']\n",
    "    pd_input.columns =  features\n",
    "    model = read_file('daily_visitors_model.joblib')             \n",
    "    prediction = model.predict(pd_input)       \n",
    "    return prediction              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10- Call UDF to forecast Daily Visitors for DAILY_VISITORS_NEW Table and save results into a Snowflake Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"CALENDAR_DATE\"  |\"DAY\"      |\"CALENDAR_MTH_DAY_NBR\"  |\"CALENDAR_MTH\"  |\"CALENDAR_YEAR\"  |\"HOLIDAY\"  |\"LAST_YEAR_DAILY_VISITORS\"  |\"FORECASTED_DAILY_VISITORS\"  |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|2022-11-01       |TUESDAY    |1                       |11              |2022             |0          |42                          |47.17447280883789            |\n",
      "|2022-11-02       |WEDNESDAY  |2                       |11              |2022             |0          |50                          |49.20104217529297            |\n",
      "|2022-11-03       |THURSDAY   |3                       |11              |2022             |0          |42                          |46.12674331665039            |\n",
      "|2022-11-04       |FRIDAY     |4                       |11              |2022             |0          |43                          |48.06638717651367            |\n",
      "|2022-11-05       |SATURDAY   |5                       |11              |2022             |1          |41                          |46.53750228881836            |\n",
      "|2022-11-06       |SUNDAY     |6                       |11              |2022             |1          |80                          |100.0980453491211            |\n",
      "|2022-11-07       |MONDAY     |7                       |11              |2022             |0          |100                         |112.0404281616211            |\n",
      "|2022-11-08       |TUESDAY    |8                       |11              |2022             |0          |109                         |117.76429748535156           |\n",
      "|2022-11-09       |WEDNESDAY  |9                       |11              |2022             |0          |40                          |44.59037780761719            |\n",
      "|2022-11-10       |THURSDAY   |10                      |11              |2022             |0          |40                          |44.854881286621094           |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load DAILY_VISITORS_NEW Table into a Snowpark DF\n",
    "NEW_VISITORS_TABLE = session.table('DAILY_VISITORS_NEW') \n",
    "\n",
    "# Apply the UDF on the Snowpark DF\n",
    "\n",
    "new_visitors_w_prediction = NEW_VISITORS_TABLE.with_column(\"FORECASTED_DAILY_VISITORS\", F.call_function(\"predict_daily_visitors\", \n",
    "                                    F.col('DAY'),\n",
    "                                    F.col('CALENDAR_MTH_DAY_NBR'),\n",
    "                                    F.col('CALENDAR_MTH'),\n",
    "                                    F.col('CALENDAR_YEAR'),\n",
    "                                    F.col('HOLIDAY'),\n",
    "                                    F.col('LAST_YEAR_DAILY_VISITORS'))\n",
    "                                    )\n",
    "\n",
    "# Show the result\n",
    "new_visitors_w_prediction.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write forecasting to a Snowflake table\n",
    "new_visitors_w_prediction.write.mode('overwrite').save_as_table('new_visitors_w_prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------- END OF THE CUMULATIVE CHALLENGE -------\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hex_info": {
   "author": "James McIntyre",
   "exported_date": "Mon Mar 10 2025 14:47:55 GMT+0000 (Coordinated Universal Time)",
   "project_id": "70dd2a3e-c68b-4b52-b832-56ae5d562af4",
   "version": "import"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
